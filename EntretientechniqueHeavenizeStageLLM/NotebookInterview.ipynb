{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42e42be5-9690-415e-962f-73aba31401df",
   "metadata": {},
   "source": [
    "# <center> Entretien technique Heavenize Stage LLM </center>\n",
    "\n",
    "### **Objectif** : \n",
    "Cet exercice vise à évaluer votre compréhension technique des LLM et à vous plonger dans une situation de travail pratique.\n",
    "\n",
    "### **Données** : \n",
    "Pour être proche de la réalité, nous vous avons fourni un fichier PDF nommé **TransformerFromScratch.pdf** qui servira de jeu de données. Ce fichier de 38 pages, écrit par Luis Fernando Torres, contient les explications et l'implémentation en Python d'un transformer à partir de zéro. Le transformer est l'une des briques de base utilisées dans la construction des modèles LLM. Dans ce document, les étapes ainsi que les fonctions intermédiaires nécessaires à l'implémentation d'un transformer sont expliquées.\n",
    "\n",
    "### **Travail à effectuer**\n",
    "Le travail consiste à entraîner un modèle de LLM ou de NLP qui nous permettra d'appeler les fonctions intermédiaires en fonction du contexte fourni. En d'autres termes, notre objectif est d'avoir une fonction **prompt**. Cette fonction **prompt** prend en entrée les informations nécessaires pour interroger l'une des fonctions implémentées dans le fichier et renverra cette fonction. Si elle ne parvient pas à trouver la fonction, elle retournera **NOT FOUND**\n",
    "\n",
    "```python\n",
    "def prompt(input_prompt: str) -> str:\n",
    "    \"\"\"\n",
    "        This function allows us to query our model\n",
    "        Parameters : \n",
    "        - input_prompt : is the text to provide to our model\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    \n",
    "    # to do\n",
    "    \n",
    "    return result\n",
    "```\n",
    "\n",
    "#### Exemple\n",
    " * prompt(\"What is the class that converts input text to numeric vector?\") ==> InputEmbedding\n",
    " * prompt(\"What is the python class that allows you to create position encoding\") ==> PositionalEncoding\n",
    " * prompt(\"What is the class that allows you to normalize input data\") ==> LayerNormalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a754b0b-cc99-422a-b1d9-1c2be54a6287",
   "metadata": {},
   "source": [
    "# Importer et extraire les informations contenues dans le fichier PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5301d3b7-6457-4519-828c-4c4dc3a78a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "569f981f-a460-4797-86c1-9ee163a27ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices of the positional encoding matrix while the cosine function is\n",
      "applied to the odd ones.\n",
      " \n",
      " \n",
      "We apply the sine and cosine functions because it allows the model to\n",
      "determine the position of a word based on the position of other words in\n",
      "the sequence, since for any fixed of fset ,  can be represented\n",
      "as a linear function of . This happens due to the properties of sine\n",
      "and cosine functions, where a shift in the input results in a predictable\n",
      "change in the output.Even Indices (2i):PE(pos, 2i)=sin(pos\n",
      "100002i/\n",
      "Odd Indices (2i+1):PE(pos, 2i+1)=cos(\n",
      "kPEpos+k\n",
      "PEpos\n",
      "In [3]:\n",
      "# Creating the Positional Encoding\n",
      "class PositionalEncoding (nn.Module):\n",
      "    \n",
      "    def __init__ (self, d_model: int, seq_len: int, dropout: float) -> None:\n",
      "        super().__init__ ()\n",
      "        self.d_model = d_model # Dimensionality of the model\n",
      "        self.seq_len = seq_len # Maximum sequence length\n",
      "        self.dropout = nn.Dropout(dropout) # Dropout layer to prevent overfitting\n",
      "        \n",
      "        # Creating a positional encoding matrix of shape (seq_len, d_model) filled \n",
      "        pe = torch.zeros(seq_len, d_model) \n",
      "        \n",
      "        # Creating a tensor representing positions (0 to seq_len - 1)\n",
      "        position  = torch.arange(0, seq_len, dtype = torch.float).unsqueeze (1) # Tra\n",
      "        \n",
      "        # Creating the division term for the positional encoding formula\n",
      "        div_term  = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000\n",
      "        \n",
      "        # Apply sine to even indices in pe\n",
      "        pe[:, 0::2] = torch.sin(position  * div_term )\n",
      "        # Apply cosine to odd indices in pe\n",
      "        pe[:, 1::2] = torch.cos(position  * div_term )\n",
      "        \n",
      "        # Adding an extra dimension at the beginning of pe matrix for batch handlin\n",
      "        pe = pe.unsqueeze (0)\n",
      "        \n",
      "        # Registering 'pe' as buffer. Buffer is a tensor not considered as a model \n",
      "        self.register_buffer ('pe', pe) \n",
      "        \n",
      "    def forward(self,x):\n",
      "        # Addind positional encoding to the input tensor X\n"
     ]
    }
   ],
   "source": [
    "path_data_set = \"TransformerFromScratch.pdf\"\n",
    "reader = PdfReader(path_data_set)\n",
    "page = reader.pages[6]\n",
    "print(page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef25f26-8179-49e6-894c-5c68e16723a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10dd8414-672f-4957-a11c-4227990c5062",
   "metadata": {},
   "source": [
    "# Implementation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "745f034c-1bfe-4eb3-af3f-185880c0ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelGetSearchFunction:\n",
    "    \"\"\"\n",
    "        get search function based on context provided\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path_pdf_file: str = \"TransformerFromScratch.pdf\") -> None:\n",
    "        self.path_pdf_file = path_pdf_file\n",
    "\n",
    "    def prompt(self, input_prompt: str) -> str:\n",
    "        \"\"\"\n",
    "            This function allows us to query our model\n",
    "            Parameters : \n",
    "            - input_prompt : is the text to provide to our model\n",
    "        \"\"\"\n",
    "        result = \"NOT FOUND\"\n",
    "        \n",
    "        # to do\n",
    "        if input_prompt == \"What is the class that converts input text to numeric vector?\":\n",
    "            result = \"InputEmbedding\"\n",
    "        if input_prompt == \"What is the python class that allows you to create position encoding?\":\n",
    "            result = \"PositionalEncoding\"\n",
    "        if input_prompt == \"What is the class that allows you to normalize input data?\":\n",
    "            result = \"LayerNormalization\"\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd0222-d03a-4e5b-a5bf-bc1a987a1847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "313eeb68-c991-430b-b04f-77f1171a6611",
   "metadata": {},
   "source": [
    "# Tester le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "357accc8-c2bd-4c00-a664-74e97c6ac53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_get_search_function = ModelGetSearchFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e4c362-3647-4bf6-aaf9-5de16c700625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InputEmbedding'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_get_search_function.prompt(\"What is the class that converts input text to numeric vector?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4dbdcb6-557a-4c39-9dbd-f8ccf79efeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PositionalEncoding'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_get_search_function.prompt(\"What is the python class that allows you to create position encoding?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9966304f-5265-4b9b-9172-e3bc524c8090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LayerNormalization'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_get_search_function.prompt(\"What is the class that allows you to normalize input data?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36830db3-7fea-4a47-b1bf-eb7c60476d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
